{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sub = pd.read_csv(\"gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = train['Age'].fillna(train['Age'].mean())\n",
    "test['Age'] = test['Age'].fillna(test['Age'].mean())\n",
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "all_X = train[sel]\n",
    "all_y = train['Survived']\n",
    "\n",
    "last_X_test = test[sel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_X, #입력\n",
    "                                                    all_y, #출력\n",
    "                                                    stratify=all_y,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=77) # train 7, test3으로 나뉨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사결정 트리 만들고 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6082089552238806\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "acc_tr = model.score(X_train, y_train)\n",
    "acc_test = model.score(X_test, y_test)\n",
    "print(acc_tr)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1, acc_tr: 0.6211878009630819, acc_test: 0.5970149253731343\n",
      "max_depth: 2, acc_tr: 0.6918138041733547, acc_test: 0.6604477611940298\n",
      "max_depth: 3, acc_tr: 0.7255216693418941, acc_test: 0.664179104477612\n",
      "max_depth: 4, acc_tr: 0.7512038523274478, acc_test: 0.6977611940298507\n",
      "max_depth: 5, acc_tr: 0.7704654895666132, acc_test: 0.7052238805970149\n",
      "max_depth: 6, acc_tr: 0.8009630818619583, acc_test: 0.6791044776119403\n",
      "max_depth: 7, acc_tr: 0.8298555377207063, acc_test: 0.6604477611940298\n",
      "max_depth: 8, acc_tr: 0.8683788121990369, acc_test: 0.667910447761194\n",
      "max_depth: 9, acc_tr: 0.9052969502407705, acc_test: 0.6268656716417911\n",
      "max_depth: 10, acc_tr: 0.9325842696629213, acc_test: 0.6529850746268657\n"
     ]
    }
   ],
   "source": [
    "depth_param = range(1,11) #max_depth: 분기되는 갯수\n",
    "\n",
    "for i in depth_param:\n",
    "    model = DecisionTreeClassifier(max_depth=i).fit(X_train, y_train)\n",
    "    acc_tr = model.score(X_train, y_train)\n",
    "    acc_test = model.score(X_test, y_test)\n",
    "    print(\"max_depth: {}, acc_tr: {}, acc_test: {}\".format(i, acc_tr, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* max_depth = 5일 때가 가장 일반화된 모델 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, acc_tr: 1.0, acc_test: 0.5970149253731343\n",
      "k: 2, acc_tr: 0.7993579454253612, acc_test: 0.6455223880597015\n",
      "k: 3, acc_tr: 0.7897271268057785, acc_test: 0.6082089552238806\n",
      "k: 4, acc_tr: 0.7319422150882825, acc_test: 0.6492537313432836\n",
      "k: 5, acc_tr: 0.7367576243980738, acc_test: 0.6268656716417911\n",
      "k: 6, acc_tr: 0.7207062600321027, acc_test: 0.6716417910447762\n",
      "k: 7, acc_tr: 0.7126805778491172, acc_test: 0.664179104477612\n",
      "k: 8, acc_tr: 0.7014446227929374, acc_test: 0.6529850746268657\n",
      "k: 9, acc_tr: 0.7126805778491172, acc_test: 0.6716417910447762\n",
      "k: 10, acc_tr: 0.6998394863563403, acc_test: 0.6380597014925373\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = range(1,11) #max_depth: 분기되는 갯수\n",
    "\n",
    "for i in n_neighbors:\n",
    "    model = KNeighborsClassifier(n_neighbors=i).fit(X_train, y_train)\n",
    "    acc_tr = model.score(X_train, y_train)\n",
    "    acc_test = model.score(X_test, y_test)\n",
    "    print(\"k: {}, acc_tr: {}, acc_test: {}\".format(i, acc_tr, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C : 1e-05\n",
      "학습용 세트 점수 : 0.65971\n",
      "테스트 세트 점수 : 0.66045\n",
      "C : 0.0001\n",
      "학습용 세트 점수 : 0.66453\n",
      "테스트 세트 점수 : 0.66045\n",
      "C : 0.001\n",
      "학습용 세트 점수 : 0.68058\n",
      "테스트 세트 점수 : 0.66418\n",
      "C : 0.01\n",
      "학습용 세트 점수 : 0.69984\n",
      "테스트 세트 점수 : 0.69030\n",
      "C : 0.1\n",
      "학습용 세트 점수 : 0.70144\n",
      "테스트 세트 점수 : 0.72015\n",
      "C : 1\n",
      "학습용 세트 점수 : 0.69181\n",
      "테스트 세트 점수 : 0.71642\n",
      "C : 10\n",
      "학습용 세트 점수 : 0.69181\n",
      "테스트 세트 점수 : 0.72388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonjuri\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sonjuri\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "for i in param:\n",
    "    logreg = LogisticRegression(C=i).fit(X_train, y_train)\n",
    "    print(\"C : {}\".format(i))\n",
    "    print(\"학습용 세트 점수 : {:.5f}\".format(logreg.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 점수 : {:.5f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=10).fit(all_X, all_y)\n",
    "pred = model.predict(last_X_test)\n",
    "sub['Survived'] = pred\n",
    "sub.to_csv(\"fourth_sub.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "tmp = os.listdir()\n",
    "\"fourth_sub.csv\" in tmp #0.66746\n",
    "# 0.1이 학습이랑 테스트 차이가 별로 안나서 정확도가 더 높게나옴."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
